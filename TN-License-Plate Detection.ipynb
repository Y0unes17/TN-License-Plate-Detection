{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yolo image detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "\n",
    "\n",
    "# Load Yolo\n",
    "net = cv2.dnn.readNet(\"yolov3_training_1000.weights\", \"yolov3_testing.cfg\")\n",
    "\n",
    "# Name custom object\n",
    "classes = [\"mattn\"]\n",
    "\n",
    "# Images path\n",
    "images_path = glob.glob(r\"C:\\Users\\Younes\\Desktop\\yolo_custom_detection\\1.jpg\")\n",
    "\n",
    "\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "# Insert here the path of your images\n",
    "random.shuffle(images_path)\n",
    "# loop through all the images\n",
    "for img_path in images_path:\n",
    "    # Loading image\n",
    "    img = cv2.imread(img_path)\n",
    "    height, width, channels = img.shape\n",
    "\n",
    "    # Detecting objects\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Showing informations on the screen\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.3:\n",
    "                # Object detected\n",
    "                print(class_id)\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    print(indexes)\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            cropped=img[y:y+h, x:x+w]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            \n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0,255,0), 2)\n",
    "            cv2.rectangle(img, (x-2,y-2), (x+w, y-30), (0,255,0), cv2.FILLED)\n",
    "            cv2.putText(img, label,((x+5,y-5)),cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.imshow(\"Mat\", face)\n",
    "    key = cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real time YOLO Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "# Load Yolo\n",
    "net = cv2.dnn.readNet(\"yolov3_training_1000.weights\", \"yolov3_testing.cfg\")\n",
    "classes = ['mattn']\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "# Loading camera\n",
    "cap = cv2.VideoCapture(\"1.mp4\")\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "starting_time = time.time()\n",
    "frame_id = 0\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    frame=cv2.resize(frame,(480,480))\n",
    "    frame_id += 1\n",
    "    height, width, channels = frame.shape\n",
    "        # Detecting objects\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    # Showing informations on the screen\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.2:\n",
    "                # Object detected\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.4, 0.3)\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = confidences[i]\n",
    "            color = colors[class_ids[i]]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + 30), color, -1)\n",
    "            cv2.putText(frame, label + \" \" + str(round(confidence, 2)), (x, y + 30), font, 1.5, (255,255,255), 2)\n",
    "\n",
    "    cv2.imshow(\"Image\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real time Detection & Recognition TN-license plate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.59984815 0.40015182]]\n",
      "[[0.6088413  0.39115876]]\n",
      "[[0.6084149  0.39158505]]\n",
      "[[0.6072816  0.39271832]]\n",
      "[[0.6082662  0.39173383]]\n",
      "[[0.60416615 0.39583385]]\n",
      "[[0.6093661  0.39063385]]\n",
      "[[0.6124687  0.38753128]]\n",
      "[[0.60740036 0.39259967]]\n",
      "[[0.6110181  0.38898188]]\n",
      "[[0.61521506 0.38478494]]\n",
      "[[0.6192083  0.38079166]]\n",
      "[[0.6166052  0.38339472]]\n",
      "[[0.62091786 0.37908214]]\n",
      "[[0.6218247  0.37817526]]\n",
      "[[0.6214719  0.37852815]]\n",
      "[[0.62085724 0.37914276]]\n",
      "[[0.61558056 0.38441944]]\n",
      "[[0.61506134 0.38493857]]\n",
      "[[0.6146745 0.3853255]]\n",
      "[[0.609992   0.39000797]]\n",
      "[[0.6137398  0.38626018]]\n",
      "[[0.61495924 0.38504076]]\n",
      "[[0.62004566 0.37995437]]\n",
      "[[0.61671627 0.3832837 ]]\n",
      "[[0.61659056 0.38340944]]\n",
      "[[0.6173246 0.3826754]]\n",
      "[[0.61862254 0.38137752]]\n",
      "[[0.6171576  0.38284242]]\n",
      "[[0.615888 0.384112]]\n",
      "[[0.03363244 0.9663676 ]]\n",
      "[[0.03489007 0.96510994]]\n",
      "[[0.03414736 0.9658527 ]]\n",
      "[[0.03365101 0.966349  ]]\n",
      "[[0.03406595 0.96593404]]\n",
      "[[0.03397186 0.96602815]]\n",
      "[[0.0339398 0.9660602]]\n",
      "[[0.03390313 0.96609694]]\n",
      "[[0.03403068 0.9659693 ]]\n",
      "[[0.03382936 0.9661706 ]]\n",
      "[[0.03355339 0.96644664]]\n",
      "[[0.03364719 0.96635276]]\n",
      "[[0.03370684 0.9662931 ]]\n",
      "[[0.03395298 0.966047  ]]\n",
      "[[0.03365852 0.96634144]]\n",
      "[[0.03373165 0.9662683 ]]\n",
      "[[0.03358976 0.9664102 ]]\n",
      "[[0.03368689 0.9663132 ]]\n",
      "[[0.03387826 0.96612173]]\n",
      "[[0.03368077 0.96631926]]\n",
      "[[0.0336028 0.9663972]]\n",
      "[[0.03357374 0.96642625]]\n",
      "[[0.03362932 0.9663707 ]]\n",
      "[[0.03382888 0.96617115]]\n",
      "[[0.03403061 0.96596944]]\n",
      "[[0.03397812 0.96602184]]\n",
      "[[0.0339678  0.96603215]]\n",
      "[[0.03382971 0.96617025]]\n",
      "[[0.03379187 0.9662081 ]]\n",
      "[[0.0337992 0.9662008]]\n",
      "[[0.2261145  0.77388555]]\n",
      "[[0.24534267 0.7546573 ]]\n",
      "[[0.24682991 0.7531701 ]]\n",
      "[[0.24667688 0.7533231 ]]\n",
      "[[0.24651681 0.7534832 ]]\n",
      "[[0.24697167 0.7530284 ]]\n",
      "[[0.24710004 0.75289994]]\n",
      "[[0.24641241 0.7535876 ]]\n",
      "[[0.2469175 0.7530825]]\n",
      "[[0.24689853 0.7531015 ]]\n",
      "[[0.24612552 0.7538745 ]]\n",
      "[[0.24663244 0.7533676 ]]\n",
      "[[0.24694952 0.75305045]]\n",
      "[[0.24611472 0.75388527]]\n",
      "[[0.24616414 0.75383586]]\n",
      "[[0.24711612 0.75288385]]\n",
      "[[0.24620086 0.75379914]]\n",
      "[[0.24628876 0.7537112 ]]\n",
      "[[0.24609934 0.75390065]]\n",
      "[[0.24656999 0.75343007]]\n",
      "[[0.24656156 0.75343853]]\n",
      "[[0.24669072 0.75330925]]\n",
      "[[0.24605311 0.75394684]]\n",
      "[[0.24596219 0.7540378 ]]\n",
      "[[0.24605285 0.7539472 ]]\n",
      "[[0.2456136 0.7543864]]\n",
      "[[0.24627653 0.7537235 ]]\n",
      "[[0.24640137 0.75359863]]\n",
      "[[0.24617334 0.7538267 ]]\n",
      "[[0.2462912 0.7537087]]\n",
      "[[0.9846987  0.01530131]]\n",
      "[[0.986339   0.01366102]]\n",
      "[[0.9865463  0.01345376]]\n",
      "[[0.9865834  0.01341663]]\n",
      "[[0.9864877  0.01351232]]\n",
      "[[0.98667777 0.01332226]]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "import base64 \n",
    "from io import BytesIO \n",
    "import json \n",
    "import random \n",
    "import cv2 \n",
    "from keras.models import load_model \n",
    "import numpy as np \n",
    "threshold = 0.5 \n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image \n",
    "model = keras.models.load_model('mattn.h5')\n",
    "\n",
    "# Load Yolo\n",
    "net = cv2.dnn.readNet(\"yolov3_training_1000.weights\", \"yolov3_testing.cfg\")\n",
    "classes = ['mattn']\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "# Loading camera\n",
    "cap = cv2.VideoCapture(\"2.mp4\")\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    frame=cv2.resize(frame,(640,480))\n",
    "    height, width, channels = frame.shape\n",
    "        # Detecting objects\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    # Showing informations on the screen\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "   \n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.2:\n",
    "                # Object detected\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.4, 0.3)\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]     \n",
    "            mat=framemat=frame[y:y+h, x:x+w]\n",
    "            \n",
    "            if type(mat) is np.ndarray: \n",
    "                mat = cv2.resize(frame, (224, 224))     \n",
    "                im = Image.fromarray(mat, 'RGB') \n",
    "                img_array = np.array(im) \n",
    "                img_array_expanded_dims = np.expand_dims(img_array, axis=0) \n",
    "                img_array = preprocess_input(img_array_expanded_dims)\n",
    "                pred = model.predict(img_array)\n",
    "                print(pred)\n",
    "                prediction = np.argmax(pred[0]) \n",
    "                #label=class_labels[pred.argmax()]\n",
    "                probabilityValue =np.amax(pred)\n",
    "                \n",
    "                if probabilityValue > threshold:\n",
    "\n",
    "                    if prediction==0:\n",
    "                        name='notsteal :'\n",
    "                    elif prediction==1:\n",
    "                        name='steal :'\n",
    "                        cv2.imwrite(\"Steal/\" +'StealCar'+str(y) + \".jpg\", framemat)\n",
    "                        \n",
    "                        \n",
    "                       \n",
    "                           \n",
    "            text = \"{}: {:.2f}%\".format(name, probabilityValue * 100)\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = confidences[i]\n",
    "            color = colors[class_ids[i]]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            #cv2.rectangle(frame, (x, y), (x + w, y + 30), color, -1)\n",
    "            #cv2.putText(frame, label + \" \" + str(round(confidence, 2)), (x, y + 30), font, 1.5, (255,255,255), 2)\n",
    "            cv2.putText(frame, text, ((x+5,y-5)),cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2) \n",
    "             \n",
    "    cv2.imshow(\"Image\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
